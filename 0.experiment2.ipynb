{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "# import torchvision\n",
    "# import torchvision.models as models\n",
    "# from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from functions import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from model import FineTuneModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## set path ##\n",
    "data_path = \"./ucf_image/\"    # define UCF-101 spatial data path\n",
    "action_name_path = \"./UCF101actions.pkl\"  # load preprocessed action names\n",
    "save_model_path = \"./record/\"  # save Pytorch models\n",
    "\n",
    "## gpu setting ##\n",
    "# GPU_NUM, GPU_NUM2 = 0,  2\n",
    "# device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "# device2 = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "# torch.cuda.set_device(device) # change allocation of current GPU\n",
    "# print('Current cuda device ', torch.cuda.current_device())\n",
    "\n",
    "\n",
    "# ## training parameters ##\n",
    "\n",
    "# epochs = 15\n",
    "# batch_size = 3\n",
    "# learning_rate = 1e-4\n",
    "# log_interval = 10\n",
    "# img_x, img_y = 240, 320  # resize video 2d frame size\n",
    "\n",
    "# ## model parameter ##\n",
    "# dim = 100\n",
    "# k = 101                 # number of target category\n",
    "\n",
    "# ## Loader parameter ##\n",
    "# params = {'batch_size': batch_size, 'shuffle': True}\n",
    "# ## load UCF101 actions names ##\n",
    "# with open(action_name_path, 'rb') as f:\n",
    "#     action_names = pickle.load(f)   # load UCF101 actions names    \n",
    "# action_names[58] = 'HandStandPushups' # fix the label name to match the folder name\n",
    "\n",
    "# ## convert labels -> category ##\n",
    "# le = LabelEncoder()\n",
    "# le.fit(action_names)\n",
    "# action_category = le.transform(action_names).reshape(-1, 1)\n",
    "# enc = OneHotEncoder()\n",
    "# enc.fit(action_category)\n",
    "# actions = []\n",
    "# fnames = os.listdir(data_path)\n",
    "# all_names = []\n",
    "# for f in fnames:\n",
    "#     loc1 = f.find('v_')\n",
    "#     loc2 = f.find('_g')\n",
    "#     actions.append(f[(loc1 + 2): loc2]) # 저장되어 있는 파일 순서대로 labeling\n",
    "\n",
    "#     all_names.append(f)\n",
    "    \n",
    "# ## list all data files ##\n",
    "# all_X_list = all_names              # all video file names\n",
    "# all_y_list = labels2cat(le, actions)    # all video labels\n",
    "\n",
    "# ## train, test split ##\n",
    "# train_list, test_list, train_label, test_label = train_test_split(all_X_list, all_y_list, test_size=0.25, random_state=42)\n",
    "\n",
    "# ## total 25 frames (min size) ##\n",
    "# begin_frame, end_frame, skip_frame = 1, 26, 1 \n",
    "# selected_frames = np.arange(begin_frame, end_frame, skip_frame).tolist()\n",
    "# print(\"The total Number of selected frame is\", len(selected_frames))\n",
    "\n",
    "\n",
    "# ## image transformation ##\n",
    "# transform = transforms.Compose([transforms.Resize([img_x, img_y]),\n",
    "#                                 transforms.ToTensor(),\n",
    "#                                 transforms.Normalize(mean=[0.5], std=[0.5])])\n",
    "\n",
    "# ## UCF101 30 images dataset ##\n",
    "# train_set, valid_set = Dataset_3DCNN(data_path, train_list, train_label, selected_frames, transform=transform), \\\n",
    "#                        Dataset_3DCNN(data_path, test_list, test_label, selected_frames, transform=transform)\n",
    "\n",
    "\n",
    "# train_loader = data.DataLoader(train_set, **params)\n",
    "# valid_loader = data.DataLoader(valid_set, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Pre-trained Model: vgg16\n"
     ]
    }
   ],
   "source": [
    "dim = 100\n",
    "k = 101\n",
    "learning_rate = 1e-4\n",
    "\n",
    "model = FineTuneModel(dim, k)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "model_path = './record/bin/FT_epoch1.pth'\n",
    "optim_path = './record/bin/FT_optimizer_epoch1.pth'\n",
    "\n",
    "load_model = torch.load(model_path)\n",
    "load_optim = torch.load(optim_path)\n",
    "model.load_state_dict(load_model)\n",
    "optimizer.load_state_dict(load_optim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuneModel(\n",
       "  (model): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): Conv2d(512, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=2500, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=101, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_loader:\n",
    "    y_pred = []\n",
    "    for i, x_in in enumerate(x):\n",
    "        print(i)\n",
    "        y_pred.append(model(x_in))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 37\n",
      "1 1\n",
      "85 85\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(torch.argmax(y_pred[i]).item(), y[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.33333333, 0.        , ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [1.        , 1.        , 0.66666667, ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.66666667, 1.        , 1.        , ..., 1.        , 1.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.load('./record/FTmodel_epoch_training_scores50.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_point = torch.save({\n",
    "    'model': model.state_dict(),\n",
    "    'optimizer':optimizer.state_dict()\n",
    "}, 'temp.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.load('temp.pth')\n",
    "temp['model']\n",
    "optimizer.load_state_dict(temp['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCF_DNN(nn.Module):\n",
    "    def __init__(self, h_in, h1, h2, h3, h4, h5, h_out):\n",
    "        super(UCF_DNN, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(h_in,h1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.3),\n",
    "            \n",
    "            nn.Linear(h1,h2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.3),\n",
    "            \n",
    "            nn.Linear(h2,h3),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(h3,h4),\n",
    "            nn.Dropout2d(0.3),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(h4,h_out)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 3000) # T * D \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_buffers at 0x7fd3099a3b50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(1,30,100)\n",
    "x = torch.from_numpy(x).float()\n",
    "h_in, h_out = x.shape[1]*x.shape[2]*1, 101 # UCF101\n",
    "h1, h2, h3, h4, h5 = 512, 256, 128, 128, 100 \n",
    "model = UCF_DNN(h_in, h1, h2, h3, h4, h5, h_out)\n",
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0531,  0.0224, -0.0790, -0.0024,  0.0144, -0.0745,  0.0532,  0.0710,\n",
       "          0.0454,  0.0302, -0.0307,  0.0020,  0.0172, -0.0959, -0.1060,  0.0261,\n",
       "          0.0544,  0.0692,  0.0448, -0.0510,  0.0498,  0.0439, -0.0296, -0.0382,\n",
       "         -0.0523,  0.0278, -0.0664,  0.0452,  0.0415,  0.0789, -0.0530,  0.0390,\n",
       "          0.0185, -0.0289,  0.0497,  0.0985,  0.0486, -0.0710, -0.0391,  0.0169,\n",
       "          0.0712, -0.0707, -0.1000,  0.0084, -0.0218, -0.0904,  0.0815,  0.1067,\n",
       "          0.0292,  0.0391, -0.0792, -0.0743,  0.0194,  0.0786,  0.0310,  0.0038,\n",
       "         -0.0448,  0.0006,  0.0829, -0.0061,  0.1112, -0.0627, -0.0279, -0.0282,\n",
       "         -0.0243,  0.0651,  0.0384,  0.0059, -0.0749,  0.1212, -0.0924, -0.0488,\n",
       "         -0.0269, -0.0759, -0.0449, -0.0616,  0.0267,  0.0133,  0.0639,  0.0734,\n",
       "         -0.0142,  0.0243,  0.0773,  0.0502,  0.0371,  0.0505, -0.0336,  0.0541,\n",
       "         -0.0254,  0.0166,  0.1035,  0.0070, -0.0716, -0.0819,  0.0651,  0.1369,\n",
       "          0.0101,  0.0108,  0.0393, -0.0365, -0.0199]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1f8a688cae5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms-tcn",
   "language": "python",
   "name": "ms-tcn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
